---
title: '02.phyloseq_ASV_Table'
project: "Jech et al. Biocrust Cultivation"
author: "Sierra Jech"
lab: "Barger Lab"
date: "2024-10-24"
output: html_document
---

# Purpose
- Use phyloseq to manipulate the ASV table. Remove irrelevant samples, apply a prevalence filter, and more
- Look at blank samples and assess contamination potential
- Output a usable ASV table for analyses

# Setup
The original mapping file was modified to include only samples of interest for this project. The sequencing run included many different projects together. 

## Libraries

```{r}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(phyloseq) # For all bioinformatics analyses post Dada2
packageVersion('phyloseq')
library(ggplot2)
```

## Read Data 

# Load the ASV table (called OTU in phyloseq)
```{r}


list.files()
otumat <- read.table(file = "data/seqtab_wTax_mctoolsr_17032022.txt",header=T)
dim(otumat) # 386 samples and 31,931 ASVs but we will drop many of these samples when we load the mapping table
otumat <- otumat %>%
  tibble::column_to_rownames("X.ASV_ID") # push the ASV_ID column into the rownames position

```

# Load the taxonomy table - this comes from two columns in the dada2 output
```{r}
# Find the ASV names
asv <- rownames(otumat)
# Find the taxonomy info
tax <- otumat$taxonomy
# Combine them into a dataframe
taxmat <- as.data.frame(cbind(asv, tax)) 
# change the column names to be "ASV_ID" and taxonomy
colnames(taxmat) <- c("ASV_ID", "taxonomy")
# split the column into each taxonomy
taxmat <- separate(taxmat, 
                   col = taxonomy, 
                   into= c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species"), sep = ";")
```

# Format tax_sep for phyloseq by making ASV_ID the rownames
```{r}
taxmat <- taxmat %>%
  tibble::column_to_rownames("ASV_ID")
# Delete the species column because it is ASV_ID (it is in column 7)
taxmat <- taxmat[, 1:6]
# remove the taxonomy column from the OTU table (it is column 385)
otumat <- otumat[, -385]
```

# Load the data mapping (metadata) file
```{r}
#list.files()
mapping <- read.table("data/cesu_mapping_17032022_subset.txt", header = TRUE) # all metadata
colnames(mapping)
mapping <- remove_rownames(mapping)
sampledata <- column_to_rownames(mapping, var = "SampleID") # rownames should be the sample IDs
```

# Transform to phyloseq objects

```{r}
# check that the names match
all.equal(sort(colnames(otumat)), sort(rownames(sampledata)))

# they do not match because I am working with fewer samples than were in the total sequencing run
samples <- row.names(sampledata)
# subset the otumat for only the samples in the list I just made
otumat_subset <- otumat[ ,samples] # here I get rid of the extra samples so now we have the samples we want and all the relevant blanks (213 total)
# check that the names match
all.equal(sort(colnames(otumat_subset)), sort(rownames(sampledata))) 
colnames(otumat_subset)
```

# Transform otu table and taxonomy tables into matrices
```{r}
otumat <- as.matrix(otumat_subset)
taxmat <- as.matrix(taxmat)
#View(otu_mat)
OTU = otu_table(otumat, taxa_are_rows = TRUE)
TAX = tax_table(taxmat)
samples = sample_data(sampledata)
cesu_16S_raw.ps <- phyloseq(OTU, TAX, samples)
cesu_16S_raw.ps
# checks out

# Check on the naming
colnames(otu_table(cesu_16S_raw.ps)) # names associated with the otu table
sample_names(cesu_16S_raw.ps) #names associated with the mapping table
sample_variables(cesu_16S_raw.ps)
sample_sums(cesu_16S_raw.ps) #returns the ASV count for each sample
```

# Get Phylum counts
```{r}
rank_names(cesu_16S_raw.ps)
table(tax_table(cesu_16S_raw.ps)[, "Phylum"], exclude = NULL) # 46 phyla including NA
# probably want to remove the NA phyla and the phyla with only 1 feature
cesu_16S_removeNA.ps <- subset_taxa(cesu_16S_raw.ps, !is.na(Phylum))
```

# Prevalence
```{r}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(cesu_16S_removeNA.ps),
               MARGIN = ifelse(taxa_are_rows(cesu_16S_removeNA.ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(cesu_16S_removeNA.ps),
                    tax_table(cesu_16S_removeNA.ps))
head(arrange(prevdf,-TotalAbundance))
head(arrange(prevdf,-Prevalence)) # no ASVs are found in every sample
#prevdf
# note, there are 213 samples including many blanks. The prevalence column gives me a count of the number of samples which have that ASV. We do not really have a reason to limit the prevalence of ASVs in the analysis. 
# note, the Total Abundance column is "the sum of all reads observed for each ASV". When people say that they removed rare species which had < 1% abundance...they are talking about an abundance cutoff. The phyloseq manual uses a prevalence cutoff of 5%. 
# Note that there are ASVs present in the list which have zero Total Abundance. They should be removed

# CONTINUE PREVAENCE CODE HERE IF DESIRED
#prevalenceThreshold = 0.05 * nsamples(mayberrycyano_16S_removeNA.ps) # remove ASVs which are present in less than 5% of samples. The problem with this cut off right now is that I have included all the blanks in the dataset, so we should wait to do a prevalence cutoff until they are removed. 
#prevalenceThreshold # so they have to be in at least 2.5 samples to be included in the analysis

#Are there phyla that are comprised of mostly low-prevalence features? Compute the total and average prevalence of the features in each phylum.
#plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
# now prune those with a prevalence < 5%
#keepTaxa = rownames(prevdf)[(prevdf$Prevalence >= prevalenceThreshold)]
#pits_16S_rmNAPhyla_prevalent.ps = prune_taxa(keepTaxa, pits_16S_rmNAPhyla.ps)

# check your work
#table(tax_table(pits_16S_rmNAPhyla_prevalent.ps)[, "Phylum"], exclude = NULL)
# this table is much smaller, I think it tells us the number of ASVs in each phylum
```

# FILTER OUT MITOCHONDRIA, CHLOROPLASTS, and KINGDOM EUKARYOTA
# chloroplast is an order and mitochondria is a family in this version of SILVA
```{r}
# Get taxonomy table out of phyloseq:
cesu_taxTable <- psmelt(cesu_16S_removeNA.ps) # this takes some time

# First check what will be removed
tax_filt <- cesu_taxTable %>%
  filter(Order != "Chloroplast") %>%
  filter(Family != "Mitochondria") %>%
  filter(Kingdom != "Eukaryota") %>%
  filter(Kingdom != "NA") %>% #Remove ASVs where kingdom is unknown ("NA" in first column)
  filter(Phylum != "NA") #Remove ASVs where phylum is unknown ("NA" in second column) # many will be removed!
#keeps 5,814,687 ASVs (duplicates due to samples are included in this so not unique ASVs)

# How many were removed?
dim(cesu_taxTable)[1]
dim(cesu_taxTable)[1] - dim(tax_filt)[1] # tells you how many are removed
# We will filter out a total of 5814687 instances of ASVs
986616/6801303# We are removing 14.5% of ASV instances
(6801303-986616)/6801303# We are keeping 85.5% of ASV instances

# Now actually remove them from the pyloseq object. First find and save each set as their own object. We will then remove all the ones we do not want below. 
# Chloroplasts (order)
chloros <- cesu_taxTable %>%
  filter(Order == "Chloroplast")
dim(chloros) #163200 chloroplast ASVs
chloro_names <- chloros$OTU
chloro_names <- unique(chloro_names)
length(chloro_names) #425 unique chloroplast ASVs are being removed 

# Mitochondria (family)
mitos <- cesu_taxTable %>%
  filter(Family == "Mitochondria")
dim(mitos) #1159680 mitochondria ASVs
mito_names <- mitos$OTU
length(mito_names)
mito_names <- unique(mito_names)
length(mito_names) #3020 unique chloroplast ASVs are being removed 

# Eukaryota (kingdom)
kingdomEuks <- cesu_taxTable %>%
  filter(Kingdom == "Eukaryota")
dim(kingdomEuks) #0
euks_names <- rownames(kingdomEuks)
euks_names

# NA's (kingdom) - these were removed above as NA's
# kingdomNAs <- pits_taxTable %>%
#   filter(Kingdom == "NA")
# dim(kingdomNAs) #0
# kNAs_names <- rownames(kingdomNAs)

# NA's (phyla)
PhylumNAs <- cesu_taxTable %>%
  filter(Phylum == "NA")
dim(PhylumNAs) #252831
pNAs_names <- PhylumNAs$OTU
pNAs_names <- unique(pNAs_names)
length(pNAs_names) #1187

# Since this is a subset of a full sequencing run, some of the ASVs have no reads. We need to remove them
prevdf_zero <- prevdf %>%
  filter(TotalAbundance == 0)
#how many are kept?
31931 - 10993 #20938 kept
20938/31931 # keeping 65.6% that are not zero
# make a list of the ones we want to remove
taxa_zero_abundance <-  row.names(prevdf_zero)

# join all ASV IDs that should be removed into one list
remove_ASVs <- c(chloro_names, mito_names, euks_names, pNAs_names, taxa_zero_abundance)
length(remove_ASVs) # removing thousands instances of ASVs, SDJ updated this to be just the unique ones which is 15625 ASVs removed
#check it with real math
10993+3020+0+1187+425 # 15625 instances of ASV's is a smaller number than the list we created because there are still some duplicates 
# are there duplicates?
temp <- remove_ASVs[!duplicated(remove_ASVs)]
length(temp) # there are only 13895 ASVs that we are actually removing

# Removing ASVs in phyloseq comes from: Joey711's code: https://github.com/joey711/phyloseq/issues/652
# Remove the ASVs that identified:
all_Taxa <- taxa_names(cesu_16S_removeNA.ps) #get all tax names in original, uncleaned dataset
ASVstoKeep <- all_Taxa[!(all_Taxa %in% temp)]
length(ASVstoKeep) #18036
cesu_16S_ps <- prune_taxa(ASVstoKeep, cesu_16S_removeNA.ps) # new phyloseq object with just the taxa we want!
```

# Get Phylum counts again 
```{r}
rank_names(cesu_16S_ps)
table(tax_table(cesu_16S_ps)[, "Phylum"], exclude = NULL) #45
#### Prevalence ####
# Compute prevalence of each feature, store as data.frame
prevdf_filt = apply(X = otu_table(cesu_16S_ps),
                    MARGIN = ifelse(taxa_are_rows(cesu_16S_ps), yes = 1, no = 2),
                    FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf_filt = data.frame(Prevalence = prevdf_filt,
                         TotalAbundance = taxa_sums(cesu_16S_ps),
                         tax_table(cesu_16S_ps))
head(arrange(prevdf_filt,-TotalAbundance))
head(arrange(prevdf_filt,-Prevalence))
# there should be no chloroplast, mitochondria reads in the dataset anymore. We should also not have any ASVs without reads or with NA kingdom or phyla assignments
```

# Checking the data
Code here is modified from Cliff Tutorial
```{r}
# again calculate the number of ASV per sample
sort(phyloseq::sample_sums(cesu_16S_ps)) 
sample_reads <- as.data.frame(phyloseq::sample_sums(cesu_16S_ps))
sample_reads <- rownames_to_column(sample_reads)
colnames(sample_reads) <- c("Sample", "reads")
sample_reads$type <- "sample"
sample_reads$type[196:213] <- "blank"
sample_reads$type[192] <- "blank"
sample_reads$type[118:119] <- "blank"
sample_reads[order(sample_reads$reads), ] # more blanks than samples = cesu326Blank19,  cesu315Blank45DNA, cesu316Blank5, cesu318Blank9
sample_reads %>% group_by(type) %>% summarise(minReads = min(reads),
                                              maxReads = max(reads),
                                              meanReads = mean(reads),
                                              sumReads = sum(reads))
# type   minReads maxReads meanReads  sumReads
# blank       177    11751     2902.  60943
# sample     4610    47282    23141.  4442982
# These metrics include samples from Gh0, GH2, MB1, MB2, R0, R2, blanks, and initials. All of these are in some way used in the manusript (not for all analyses, but at least in 1), so I think it is ok to include them in these numbers...some of the blanks can be removed though. This is done below. 

#mean(phyloseq::sample_sums(cesu_16S_ps))
# mean reads per sample = 21,145.2 including blanks

# How are number of reads distributed across the samples?
seqcounts <- as.data.frame(sort(colSums(otu_table(cesu_16S_ps)))) %>%
  rename("seqs" = "sort(colSums(otu_table(cesu_16S_ps)))") %>%
  rownames_to_column(var = "sampleID")
head(seqcounts, 10)
tail(seqcounts,10)

# Now we have a dataframe with two columns, seqs and sampleID which we can plot
ggplot(seqcounts, aes(reorder(sampleID, seqs, mean), seqs)) + # Dataframe and variables
  geom_bar(stat = "identity") + # Type of graph
  labs(y = "# Reads", x = "Sample") + # Axes labels
  coord_flip() + # Flip axes
  geom_hline(yintercept = 8000, color = "blue") + # this seems backwards because of the coord_flip() command above
  theme_classic() + 
  theme(axis.text.y = element_text(size = 2)) # rarefaction at 8000 looks ok to me because it makes the blanks drop out, keeps as many possible reads as possible, and we only lose 1 relevant? sample
colSums(otu_table(cesu_16S_ps)) # all read counts are different
sum(colSums(otu_table(cesu_16S_ps))) # total number of reads in the dataset is 4,503,925
```

# Save these Pre-Processing Steps so that you do not have to do them again
```{r}
save(cesu_16S_ps, file = "data_output/cesu_processed_filt_ps.RData")
saveRDS(cesu_16S_ps, file = "data_output/cesu_processed_filt_ps.rds")
```


## Blank Analysis ##
Check the ASVs that are in the blanks
```{r}
# subset for the blank samples that are relevant 
samplesToKeep <- c("cesu305Blank3DNA", "cesu312Blank42DNA", "cesu313Blank43DNA", "cesu314Blank44DNA", "cesu316Blank5", "cesu317Blank7", "cesu318Blank9", "cesu319Blank11", "cesu320Blank12", "cesu321Blank15", "cesu322Blank14", "cesu324Blank17", "cesu325Blank18", "cesu326Blank19", "cesu327Blank20", "cesu328Blank21")

# Then recalculate the sample_reads statistics for the subset of relevant blanks
sample_reads %>% 
  filter(Sample %in% samplesToKeep) %>%
  #group_by(type) %>% 
  summarise(minReads = min(reads),
            maxReads = max(reads),
            meanReads = mean(reads),
            sumReads = sum(reads))

# which blank has 11,751 reads and how many samples does it belong with?
#cesu318Blank9 and it goes with the following samples:
# cesu239R0GMJAD21a - # reads = 24514
# cesu243R0FCPAE4a - # reads = 25594
# cesu246R0FMJAD14a - # reads = 18321
# cesu250R0ControlD16a - # reads = 37113
# cesu259R0GMJASE2a - # reads = 29280
# cesu263R0FCPAJCE5a - # reads = 25378
# blank5 also has a high number of reads with 4 associated samples 


#allblanks <- c("cesu305Blank3DNA","cesu310Blank40DNA","cesu311Blank41DNA", "cesu312Blank42DNA", "cesu313Blank43DNA", "cesu314Blank44DNA", "cesu315Blank45DNA", "cesu316Blank5", "cesu317Blank7", "cesu318Blank9", "cesu319Blank11", "cesu320Blank12", "cesu321Blank15", "cesu322Blank14", "cesu324Blank17", "cesu325Blank18", "cesu326Blank19", "cesu327Blank20", "cesu328Blank21", "cesu152Blank30DNA820", "cesu192Blank")

blanks <- prune_samples(sample_names(cesu_16S_ps) %in% samplesToKeep , cesu_16S_ps)
sample_names(blanks)
colSums(otu_table(blanks)) # number of reads in these samples
mean(colSums(otu_table(blanks))) # 2705.8
table(tax_table(blanks)[, "Phylum"], exclude = NULL) # 40 phyla represented
melt_blanks <- psmelt(blanks)
# plot it 
blanks.phylum = tax_glom(blanks, taxrank="Phylum", NArm=FALSE)
plot_bar(blanks.phylum, fill="Phylum")
#ggsave("output/blanks_taxonomy.pdf", width = 10, height = 10)

count_blank_phyla <- melt_blanks %>% group_by(Sample,Phylum, OTU, Abundance) %>% summarise(number = n())
# Blank9
count_blank9 <- count_blank_phyla %>% filter(Sample == "cesu318Blank9") %>% filter(Abundance > 0)
# there is evidence of contamination here. Blank9 was severely contaminated with Firmicute (ASV_256). There are some patterns here which could be extracted from samples at some point. 
count_blank_phyla %>% filter(OTU == "ASV_256") # this ASV is only over abundant in blank9.
# check for this ASV in the larger dataset
cesu_taxTable %>% filter(OTU == "ASV_256") %>% select(Sample, Abundance) # this ASV is only over abundant in Blank9. It is present in 5 real samples and none of them match the samples which were in the same extraction run as Blank9. So not a systematic contamination
# Blank5
count_blank5 <- count_blank_phyla %>% filter(Sample == "cesu316Blank5") %>% filter(Abundance > 0)
# the highest count for an ASV is for ASV_476
count_blank_phyla %>% filter(OTU == "ASV_476")
cesu_taxTable %>% filter(OTU == "ASV_476") %>% select(Sample, Abundance) # not a concern

```

## Renaming Cyanos with Cydrasil and iTol 
```{r}
# if starting here, simply load the phyloseq file (no need to run all of the code above)
cesu_16S_ps <- readRDS("data_output/cesu_processed_filt_ps.rds")
cesu_16S_ps@sam_data
# melt the correct version of ps (filtered)
# Get taxonomy table out of phyloseq:
cesu_taxTable_filt <- psmelt(cesu_16S_ps) # this takes some time

# Sort the entire matrix and keep entries in column "P" that are for Cyanobacteria
cyano <- cesu_taxTable_filt[ which(cesu_taxTable_filt$Phylum == "Cyanobacteria"), ]
# note that many entries have very low read counts (discard them)
# determine what level I threw away cyanoabcteria ASVs for taxonomic assignment...
# total number of reads in the Cyanobacteria dataset
sum(cyano$Abundance) # 575,890
# if I remove rows of the dataframe that have an abundance less than 50, then these are samples with 
50/575890 # .000087
(50/575890) * 100 # percent = 0.009% round up to 0.01%

cyano <- cyano %>% filter(Abundance > 50) # results in 3084 rows of data
cyano_ASVs <- unique(cyano$OTU)  # 182 unique cyano ASVs
cyano_ASVs 
cyano_ASVs <- as.data.frame(cyano_ASVs)

# trying to calculate a better metric of which ASVs were reassigned and which were not
temp <- cyano %>% group_by(OTU) %>% summarise(sumReads = sum(Abundance))
temp$readpercent <- (temp$sumReads / 575890) * 100
temp <- temp[order(temp$readpercent), ] 
# output a csv that I can work with in Excel
#write.csv(cyano_ASVs, "data_output/cesu_cyano_filt.csv", row.names = FALSE)

# Next, I need to report the total percent of cyano reads that were reassigned
sum(temp$readpercent)
sum(temp$sumReads)
509915/575890 * 100

```

# next steps:
1) load the repset file and subset it for these 289 ASVs then generate a fasta file and upload in iTOL
```{r}
#BiocManager::install("Biostrings")
library("Biostrings")

# Load the fasta file and read it into a dataframe
fastaFile <- readDNAStringSet("data/cesu16S_17032022_repset.fasta")
seq_name = names(fastaFile)
sequence = paste(fastaFile)
df <- data.frame(seq_name, sequence)

#Use string manipulations to get a column with the ASV names separate from the taxonomy
df <- separate(df, seq_name, into = c("ASV", "taxonomy"), sep = "\\s",
               extra = "merge")

# Separate the taxonomy into columns based on the semicolon
df <- separate(df, taxonomy, into = c("K", "P", "C", "O", "F", "G", "S"), sep = ";",
               extra = "merge")

# Keep entries in column "P" that are in our keep list "cyano_ASVs"
#df_cyano <- df %>% filter(P == "Cyanobacteria")
keepCyanos <- df %>% filter(ASV %in% cyano_ASVs$cyano_ASVs) # all good
# check that there are 182 of them and check their taxonomy (should all be cyanobacteria)

# output a csv that I can work with in Excel
#write.csv(keepCyanos, "data_output/cesu_182ASVs.csv", row.names = FALSE)
```


```{r}
# load the previous 195 ASV list
mbcyano195ASVs <- read.csv("data/mbCyano_195ASVs.csv")
previousASVnames <- mbcyano195ASVs$ASV
# keep the difference (289-195) ASVs which were not previously renamed with Cydrasil
cesu_cyanoASVs <- as.data.frame(keepCyanos$ASV[!(keepCyanos$ASV %in% previousASVnames)]) #70 of them
colnames(cesu_cyanoASVs) <- 'ASV'
# make sure this is correct 
sum(keepCyanos$ASV %in% previousASVnames)
112+70 # so there was not perfect overlap in these lists

# export this dataset
#write.csv(cesu_cyanoASVs, "data_output/cesu_cyanoASVs.csv", row.names = FALSE)
```

#Once finished, make a .fasta file with only these cyanobacteria so that it can go into iTol and be given new taxonomy
```{r}
#delete the SILVA taxonomy columns and keep only the 94 I need
temp <- df %>% filter(ASV %in% cesu_cyanoASVs$ASV)
cesu_cyanoASVs_subset <- subset(temp, select = c("ASV","sequence")) # format new_df = subset(df, select = c(col1, col2))

# write the cyano dataframe into fasta file
# Function below from: https://bootstrappers.umassmed.edu/guides/main/r_writeFasta.html
writeFasta<-function(data, filename){
  fastaLines = c()
  for (rowNum in 1:nrow(data)){
    fastaLines = c(fastaLines, as.character(paste(">", data[rowNum,"ASV"], sep = "")))
    fastaLines = c(fastaLines,as.character(data[rowNum,"sequence"]))
  }
  fileConn<-file(filename)
  writeLines(fastaLines, fileConn)
  close(fileConn)
}

#writeFasta(cesu_cyanoASVs_subset, "data_output/cesu_cyanoASVs.fasta")
```

